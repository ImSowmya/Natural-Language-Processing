{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language. The ultimate goal of NLP is to enable computers to understand, interpret, and respond to human languages in a way that is both meaningful and useful. This involves a range of computational techniques including text analysis, machine translation, and speech recognition.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = corpus.lower()\n",
    "text = re.sub(r\"[^a-z]\",\" \",text)\n",
    "text = re.sub(r\"\\s+\", \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural language processing nlp is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language the ultimate goal of nlp is to enable computers to understand interpret and respond to human languages in a way that is both meaningful and useful this involves a range of computational techniques including text analysis machine translation and speech recognition']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = sent_tokenize(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['natural', 'language', 'processing', 'nlp', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'natural', 'language', 'the', 'ultimate', 'goal', 'of', 'nlp', 'is', 'to', 'enable', 'computers', 'to', 'understand', 'interpret', 'and', 'respond', 'to', 'human', 'languages', 'in', 'a', 'way', 'that', 'is', 'both', 'meaningful', 'and', 'useful', 'this', 'involves', 'a', 'range', 'of', 'computational', 'techniques', 'including', 'text', 'analysis', 'machine', 'translation', 'and', 'speech', 'recognition']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "words = [word_tokenize(sentence) for sentence in sentences]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['natural', 'language', 'processing', 'nlp', 'field', 'artificial', 'intelligence', 'focuses', 'interaction', 'computers', 'humans', 'natural', 'language', 'ultimate', 'goal', 'nlp', 'enable', 'computers', 'understand', 'interpret', 'respond', 'human', 'languages', 'way', 'meaningful', 'useful', 'involves', 'range', 'computational', 'techniques', 'including', 'text', 'analysis', 'machine', 'translation', 'speech', 'recognition']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words(\"english\")\n",
    "\n",
    "words_wo_stopwords = [[word for word in sent if word not in stopwords] for sent in words]\n",
    "print(words_wo_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(words_wo_stopwords, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'natural': 0,\n",
       " 'language': 1,\n",
       " 'nlp': 2,\n",
       " 'computers': 3,\n",
       " 'interpret': 4,\n",
       " 'processing': 5,\n",
       " 'field': 6,\n",
       " 'artificial': 7,\n",
       " 'intelligence': 8,\n",
       " 'focuses': 9,\n",
       " 'interaction': 10,\n",
       " 'humans': 11,\n",
       " 'ultimate': 12,\n",
       " 'goal': 13,\n",
       " 'enable': 14,\n",
       " 'understand': 15,\n",
       " 'recognition': 16,\n",
       " 'speech': 17,\n",
       " 'human': 18,\n",
       " 'languages': 19,\n",
       " 'way': 20,\n",
       " 'meaningful': 21,\n",
       " 'useful': 22,\n",
       " 'involves': 23,\n",
       " 'range': 24,\n",
       " 'computational': 25,\n",
       " 'techniques': 26,\n",
       " 'including': 27,\n",
       " 'text': 28,\n",
       " 'analysis': 29,\n",
       " 'machine': 30,\n",
       " 'translation': 31,\n",
       " 'respond': 32}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00219659, -0.00971296,  0.00929305,  0.00203607, -0.0011625 ,\n",
       "       -0.00550674, -0.00851174, -0.00990463,  0.00894523, -0.00250099,\n",
       "        0.00459389, -0.004521  ,  0.00996131,  0.0036573 ,  0.00102442,\n",
       "       -0.00404092,  0.00121339, -0.00265223,  0.00735535,  0.00447684,\n",
       "        0.00098931,  0.00348565,  0.00371415, -0.0067858 ,  0.00893691,\n",
       "        0.00173353, -0.00579099,  0.00866208, -0.00129169,  0.00818622,\n",
       "       -0.00150334,  0.00699166,  0.00273032, -0.00435728, -0.00375262,\n",
       "        0.00919494,  0.00159305, -0.00600667,  0.00034951, -0.00196076,\n",
       "        0.00158477, -0.0077145 ,  0.00738523,  0.00130883,  0.00787672,\n",
       "        0.0044565 , -0.00439701,  0.00375543, -0.00063734, -0.00985269,\n",
       "        0.0082434 ,  0.0096544 ,  0.0096539 , -0.00379708, -0.008449  ,\n",
       "        0.00482512, -0.00765732,  0.00853388,  0.0027622 ,  0.00560622,\n",
       "        0.00611605,  0.00046693, -0.00209293,  0.00077323,  0.0098339 ,\n",
       "       -0.00712935, -0.00155713, -0.00236311,  0.00487026,  0.00645096,\n",
       "       -0.00413   ,  0.00362501, -0.0044816 ,  0.00326849,  0.00817042,\n",
       "        0.00362498, -0.00457178, -0.00301233,  0.00786858,  0.00960716,\n",
       "        0.00581925, -0.0032765 , -0.00182798, -0.00625463, -0.00429641,\n",
       "        0.00337289, -0.0064915 , -0.00661773,  0.00811602,  0.00950883,\n",
       "        0.00813913,  0.00151534, -0.0087973 , -0.00759634,  0.0015754 ,\n",
       "       -0.00953057, -0.00741529,  0.00202349, -0.00291668, -0.00915696],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('field', 0.3041238486766815),\n",
       " ('natural', 0.19579482078552246),\n",
       " ('languages', 0.1889905482530594),\n",
       " ('techniques', 0.1672196239233017),\n",
       " ('recognition', 0.14186517894268036),\n",
       " ('focuses', 0.12706628441810608),\n",
       " ('machine', 0.11620384454727173),\n",
       " ('including', 0.0636691004037857),\n",
       " ('meaningful', 0.051461055874824524),\n",
       " ('artificial', 0.046723946928977966)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('text')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
